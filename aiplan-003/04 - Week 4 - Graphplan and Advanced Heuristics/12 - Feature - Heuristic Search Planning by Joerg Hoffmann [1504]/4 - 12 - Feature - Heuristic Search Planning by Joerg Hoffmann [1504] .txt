Hello, welcome, everybody to this brief
lecture here. I'm a professor of Computer
Science at Saarland University, Zabuken,
Germany and my background is mostly
academic research and planning. So, I'm
essentially a basic research guy. Here's
what I'm going to talk about today;
Heuristic Search Planning. Now, that is
one of the most prominent sub areas of
planning, and obviously, I'm going to give
you only a very brief overview in the
little time I have. So, here's the outline
of the overview, quite comprehensive, I
would say. I'm going to start with why.
Why do we want to consider Houristic
Search Planning? Well, one possible
motivation is the international planning
competition, IPC. The first edition must
run in 1998, let me start with the second
edition in the year 2000, where the clear
winner of your space on heuristic search.
We follow then a 2 year cycle. So the next
competition is in 2002, same picture. 2
years later, same picture except that as
of this time point we have a separating
satisfying planners from optimal planners.
In optimal planning, you are forced to
give a guarantee that the plan you return
is among the best possible plans. There is
no such obligation satisficing planning.
Satisficing planning traditionally
attracts the largest competition and that
was won by heuristic search. Next
competition, same picture. Next
competition, same picture. Finally, the
most recent competition was run in 2011.
So there was a three-year gap and at that
competition heuristic search emerged best
in both tracks and actually not only the
first places, but the first 12,
respectively nine places. Now, that might
seem very impressive, and it is
impressive. However, you should not take
this too seriously. Okay? First, it's only
one part of the IPC. Mainly, the fully
automatic deterministic part. There are
other parts as well. Also, this one here
is the biggest one. Second, winning the
competition doesn't mean you win life.
You're just the best planner in one
particular setup and according to one
winning particular criterion. If you have
an actual application, the winner might be
different. Finally, saying the word winner
already is not really adequate, because
these are usually complex. Events, very
complicated experiments, lots of data and
giving you just a single bit somebody won
is not a very adequate summary. So really
all I'm saying here is that these results
should give us multiplication to consider
this approach for the 12 minutes of this
lecture. Next question I'm going to answer
is what, more precisely What do I mean by
Heuristic Search Planning? What is the
basic idea? You've already learned about
the Heuristic Search in a star, so let me
just briefly remind you, what they do is a
forward search. You start at initial
state, we keep applying application
actions, generating new reachable states
until they've eventually reached the state
that satisfies the goal. The number of
states to generate might be huge millions,
billions, you name it, so we need to veg
direct to search we do this in terms of
heuristic function h which matches any
given world state into an estimate to the
distance to the goal for that state and
then we going to prefer states that appear
to be closer to the goal which our pause
raises the question where do we get this
match to function form. Now here's the
standard example, illustrating the
standard approach. Let's say the problem
is to find the route from Saarbruecken to
Edinburgh. What we do is we simplify the
problem. In this case, here, we might
choose to simplify it by just throwing
away the map, okay? Now what we do is we
solve the simpler problem in order to get
our estimate, which in this case here, may
be the straight line distance. So
heuristic functions are computed as the
solutions to simplified versions of the
problem you are interested in. That raises
the question, how are you going to do this
in planning, where your input is not one
specific problem that you can think up the
simplification for. Instead, your input
may be any problem. All y ou get as input
is the declarative description of the
problem, and you need to automatically
generate the heuristic function h. How do
we do that? Research has so far come up
with 4 ways of doing this. So we got 4
different families of heuristic function
estimating goal distance in planning. And
what follows, I'm going to very briefly
give an intuition for each of them, and it
going to start with abstractions and then
follow clockwise. Now before I actually
get into this just to mention that PDB
stands for Python Database, and MNS stands
for Merge and Shrink. I'm not going to say
anything about those, what the differences
are, what their specifics are. I'm just
going to illustrate abstractions from a
generic point of view. So, the standard
illustration where it's very easy to see
how this works is this puzzle here, the 15
puzzle. The problem is transforming the
configuration on the left into the
configuration on the right, then moving
around those tiles encrypted with the
numbers from 1 to 15. How do we simplify
this problem? Well, what we can do is just
ignore part of the description of the
problem. So in this case, I'm ignoring the
part pertaining to the tiles numbered from
8 to 15, which is a simplified problem,
namely, a much smaller and easier puzzle.
And then I'm just going to take the
distances in the smaller puzzle as my
estimates of the distances in the real
puzzle that I want to solve. That's
already all I'm going to say about
fractions. Next one up, landmarks. For
this one, I've designed a very simple
problem that is easy to understand and
illustrate. So, the problem here is for
me, I'm currently in position 1 to go over
to position 7, and get the small key and
then, carry it all the way back to
position one.
Now what is a landmark? A landmark is
defined as something that has to be true
at some point along any plan. In this case
here, for example at some point along any
plan, I am going to be at any one of those
positions, simply because I gotta move
across the entire grid. Anothe r thing is,
as you see here, position three slot. In
order to move across that, I'm going to
have to open it. So this is another
landmark. Now in order to open the lock I
need the key, which is the big key
currently in position two. Another
landmark.
Also, at some point, because I have to
transport the small key at some point, I'm
going to have it in my hand. Now there's
quite a few more things we can do here let
me stop it here. So the intuition is that
before planning starts we somehow
automatically detect these landmarks and
then they reform the items on a to do
list. And then during search, they're just
going to tick off those items, and the
number of items that are still open is
going to be our estimate. The next one up,
then, are critical path heuristics. You'll
see this is not just one heuristic, it's
parameterized, 1, 2, 3, and so on. To
illustrate, I've chosen the traveling
salesman problem, that I presume
everybody's familiar with. So you're on
this continent here. Your truck is in
Sydney. You want to visit all major
locations on the continent.
How do you simplify the problem while the
critical path answer is to look at
subproblems of a fixed size. So if you fix
the parameter to one, then what you're
looking at is the most expensive one
sub-tour, which is saying that you picked
the most distant city and just, you know,
account for the distance of going there
and back. Increasing the parameter to 2,
what we're looking at is the most
expensive 2-sub-tour. So the most
expensive pair of cities we've got to
visit and then you can scale this
arbitrarily by just selecting some
m-sub-tour on the gifts give, that gives
you the critical path heuristic parameter
n. Now obviously if you choose m to be
high enough you'll actually solve the real
problem and get an exact estimate if we
decrease m but to get this less accurate
estimates, but will cause too much less
computation time. So that's how we
trade-off computation time against the
accuracy of the lower bond we compute. And
that already brings me to the last class,
called ignoring deletes. Now, if you're
not very familiar with planning, ignoring
deletes as a word is not going to tell you
much. So let me translate, basically what
we're doing is we are simplifying the
world by the assumption That anything that
was ever true in the past will remain
forever true in the future. To illustrate,
let's say I move my truck from Sydney to
Adelaide, then afterwards, I am at
Adelaide, because I move the truck.
However, I am also still at Sydney,
because that's where the truck was before.
And thanks to this I can actually move the
same track in two locations in parallel.
So, in this example here, I'm moving it
from Sydney to Adelaide, and from Sydney
to Brisbane, and as an effect afterwards
my truck is at all three locations. Now
that might seem a little odd indeed.
Remember, this is not the real world. It's
just simplified vert was only purpose is
to compute an estimate of goal distance.
So I can keep playing the same game. I can
go from Adelaide to the next to locations,
and as an effect of executing these moves,
I'm done. I have solved the simplified
problem, I have visited all locations Now,
it might take a little time to get used
to, but if you look at the structure I've
built, that's actually kind of obvious.
It's the Minimum Spanning Tree
approximation. So the way you should read
this is, you've got a generic
simplification principle ignoring deletes.
We can apply the principle to any input
problem. If we happen to apply it to the
TSP the outcome is the minimum spanning
tree approximation that we can use to
estimate goal distance, but we could apply
the same technique to any problem. That is
already all I'm going to say about the
methods we are using And what follows, I'm
just going to briefly highlight some
interesting theory and practice results.
For theory, I've chosen to present an
overview of results that are published in
a wonderful paper by in 2009 . Now, no
need to worry. I'm not going to take you
through this in de tail.
And, definitely, I'm not going to show you
any of the proof of the properties that
show here. Let me just very briefly give
you an idea of what it means. So if you
look at this notation here, what it is
saying is that somehow landmarks are less
equal than merge and shrink. What is the
meaning of less equal here? It's a kind of
simulation property. The intuition is that
anything you can do using landmarks, you
can just as well do using merge and
shrink. More precisely, both are ways of
lower bounding goal distance. So, each of
those techniques returns a lower bond and
goal distance. Now, what this property is
saying is that, if you take any example.
And any lower bond computed using
landmarks, you can in polynomial time
compute the same or a better lower bond
using merge and shrink. Skipping forward
to the next notation, the obvious idea
here is that this is not so for pattern
databases, as opposed to merge and shrink.
So what this property has said is that
there are cases, families of planning
tasks, and lower bounds computed landmarks
that are strictly better than any lower
bound you can compute in polynomial time
using pattern databases. So much for
theory, so this is really just a brief
appetizer. For practice, I have chosen to
show you 1 of my own results. So what we
see on this slide is on the right hand,
you've got a big network. Okay? We have
some sensitive data in it. And the network
is connected to the web. Which this little
red devil here is going to exploit.
Namely, that the red devil is going to
attack the network. It's going to execute
a sequence of exploits, leading it to the
sensitive data. So, basically what we have
is a hacking situation. Why is that a
problem, a practical problem we want to
solve? Well, imagine you're running this
big internet company, and you want to make
sure this kind of stuff doesn't happen. So
outside people who are not authorized, to
not manage to get at your sensitive data.
So what you want, is want to run security
checks. One way of doi ng this is friendly
attacks. So you hire some people who will
attack your network. If they get through
to the sensitive data, you know where you
need to work in order to close that gap.
The problem is, this is not scalable.
You've got thousands of computers, as you
know, the domain changes all the time.
Every week you get new security patches in
windows and that's because some people
invented new attached, and some other
people invented new defenses against those
attacks. So you're going to be. You're
going to have to run millions of those
attacks and ideally you want it to be
automatic. And that's exactly what has
been achived with In-planning. So, at this
American company called, Core Security,
and one of their main products, they've
got my planner running. So, my planner
called, FF, controls this red devil that
runs the friendly attacks all the time,
automatically. So as we speak, my planner
is attacking the networks of some of those
big internet companies whose names you are
certainly familiar with. And that already
brings me to the conclusion, which very
simply, is if you found this interesting
at all, you might want to have a look at
my lecture slides. I've just finished
teaching a planning course, which gives a
lot more detail on all this, a
comprehensive overview of this sub area.
What you can also do is Google the name
for some of the researchers who
contributed to the area. And if your
really, deeply interested I just made a
little list here which point us to the
literature. That's it.
Thank you very much for your attention,
for having survived up to this point. I
hope you found some of it interesting.
Enjoy the rest of the course. Bye.
