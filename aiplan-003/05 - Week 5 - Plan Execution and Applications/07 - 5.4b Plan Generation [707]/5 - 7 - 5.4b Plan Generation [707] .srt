1
00:00:00,012 --> 00:00:06,843
Another implicit assumption we have made
so far, is that all the actions we execute

2
00:00:06,843 --> 00:00:11,854
are instantaneous.
A more realistic approach is to assume

3
00:00:11,854 --> 00:00:16,867
that our actions are durative, which means
they take time.

4
00:00:16,867 --> 00:00:23,633
So every action we consider takes a known
amount of time and every action have a

5
00:00:23,633 --> 00:00:29,657
start time point and a finish time point.
Now, we have already seen that the A*

6
00:00:29,657 --> 00:00:32,873
algorithm takes the action cost into
account.

7
00:00:32,873 --> 00:00:38,721
So it can search actions that have a given
cost and one approach is simply to assign

8
00:00:38,721 --> 00:00:41,838
the time they take as the cost of the
action.

9
00:00:41,838 --> 00:00:47,322
And in fact, the FF planner we have seen
last week has been extended in this way to

10
00:00:47,322 --> 00:00:51,842
take time into account.
A different approach that is often used in

11
00:00:51,842 --> 00:00:56,834
conjunction with partial plans, and
specifically, in conjunction with HTN

12
00:00:56,834 --> 00:01:01,982
planning, is to use a temporal constraint
manager as a plug-in component to the

13
00:01:01,982 --> 00:01:05,162
planner.
And there are two flavors of it that are

14
00:01:05,162 --> 00:01:08,871
quire well-known.
The first one is called the time point

15
00:01:08,871 --> 00:01:12,147
network.
A time point network simply associates all

16
00:01:12,147 --> 00:01:16,220
the time points in a given plan.
So, we have a start and a finish time

17
00:01:16,220 --> 00:01:21,030
point for each action and we can assert
relations that must hold between these

18
00:01:21,030 --> 00:01:24,597
different time points.
What we get is a network like this one

19
00:01:24,597 --> 00:01:28,944
here, where we have six time points, and
they are related by these different

20
00:01:28,944 --> 00:01:32,255
relations that we see on the edges in this
network here.

21
00:01:32,255 --> 00:01:37,856
The good news is that the consistency of
time point networks can be checked in

22
00:01:37,856 --> 00:01:41,733
polynomial time.
A more complex approach that has been

23
00:01:41,733 --> 00:01:46,785
proposed is an interval algebra.
So now, we're relating not time points to

24
00:01:46,785 --> 00:01:51,719
each other, but the intervals that
correspond to the action execution.

25
00:01:51,719 --> 00:01:56,747
So, if we have an interval i1 and an
interval i2, we can say that one interval

26
00:01:56,747 --> 00:02:01,638
must be before the other and we use this
relation b here to express this.

27
00:02:01,638 --> 00:02:06,909
What this means is that the end time point
of the first action must be genuinely

28
00:02:06,909 --> 00:02:12,233
before the beginning of the next action.
Similarly, we have other relations like

29
00:02:12,233 --> 00:02:16,905
meets where these need to be at the same
time point or overlaps where one comes

30
00:02:16,905 --> 00:02:21,504
after the other and start during and
finish are three more relations we have

31
00:02:21,504 --> 00:02:24,630
here.
As it turns out, the interval algebra is

32
00:02:24,630 --> 00:02:29,953
more expressive than time point networks.
So there are constraints you can express

33
00:02:29,953 --> 00:02:34,414
in the interval algebra that you can't
express in time point network.

34
00:02:34,414 --> 00:02:39,745
But on the downside, checking consistency
in an interval network takes exponential

35
00:02:39,745 --> 00:02:43,186
time.
One of the things that all the approaches

36
00:02:43,186 --> 00:02:47,642
we've looked at so far have in common is
that they don't learn.

37
00:02:47,642 --> 00:02:52,794
So, if we give them a planning problem to
solve, they search or use whatever

38
00:02:52,794 --> 00:02:57,000
technique to solve this problem and come
up with a solution.

39
00:02:57,000 --> 00:03:02,634
If we give them the same problem again,
it'll take exactly the same amount of time

40
00:03:02,634 --> 00:03:07,916
and resources to solve this problem.
Or if we give it a similar problem, the

41
00:03:07,916 --> 00:03:13,764
planner cannot take anything from that
similar problem to the new problem and try

42
00:03:13,764 --> 00:03:17,547
to solve it better.
So one approach was to try to apply

43
00:03:17,547 --> 00:03:23,402
learning to planning to somehow improve
the performance of the planner over time.

44
00:03:23,402 --> 00:03:28,637
So the general idea is, we let the planner
solve a series of similar planning

45
00:03:28,637 --> 00:03:34,032
problems, then, we somehow analyse what
the planner has been doing during the

46
00:03:34,032 --> 00:03:38,733
problem solving process.
And the result of this analysis should be

47
00:03:38,733 --> 00:03:44,193
something that we can feed back into the
planning process to make the plan more

48
00:03:44,193 --> 00:03:48,948
efficient on similar problems.
That is the general idea and that is what

49
00:03:48,948 --> 00:03:53,700
you would expect from human planners when
they start solving similar planning

50
00:03:53,700 --> 00:03:58,630
problems, they would get better over time.
And there are a number of ways in which

51
00:03:58,630 --> 00:04:01,576
this learning can be done.
Here are two of them.

52
00:04:01,576 --> 00:04:06,947
One is the learning of macro-operations.
So, our planning problem contains already

53
00:04:06,947 --> 00:04:11,721
a set of operators that we can use to
solve that problem, but we can increase

54
00:04:11,721 --> 00:04:16,863
that set with macro-operations that
perform larger steps in our search space.

55
00:04:16,863 --> 00:04:22,173
Of course, this is somehow similar to HTN
planning where we also had more abstract

56
00:04:22,173 --> 00:04:26,299
methods that summarize what needs to be
done at a lower level.

57
00:04:26,300 --> 00:04:31,521
Another approach that has been tried is
learning search control knowledge.

58
00:04:31,521 --> 00:04:36,978
So, during the search, we often encounter
states that have the same f values, so the

59
00:04:36,978 --> 00:04:41,621
heuristic doesn't help us to distinguish
the states from each other.

60
00:04:41,621 --> 00:04:47,203
And, search control knowledge helps us to
decide which path to explore next in our

61
00:04:47,203 --> 00:04:50,992
search space.
Another assumption we have made so far is

62
00:04:50,992 --> 00:04:56,568
that we're dealing with a single planner
that has control over all the agents that

63
00:04:56,568 --> 00:05:01,018
are executing the plan.
So in our dock-worker robot domain, when

64
00:05:01,018 --> 00:05:06,378
we were planning, we assumed that the
robots on the cranes during plan execution

65
00:05:06,378 --> 00:05:09,572
would do as they are told by the single
planner.

66
00:05:09,572 --> 00:05:13,115
However, in multi-agent planning, this is
not the case.

67
00:05:13,115 --> 00:05:17,696
So we no longer assume that we have a
single agent that is control of all the

68
00:05:17,696 --> 00:05:21,008
other agents.
Of course, this complicates the problem

69
00:05:21,008 --> 00:05:25,355
significantly and there are a number of
flavors in which this problem can be

70
00:05:25,355 --> 00:05:28,414
developed.
For example, if the agents we're dealing

71
00:05:28,414 --> 00:05:32,630
with have different beliefs about the
worlds state they are in, then, this

72
00:05:32,630 --> 00:05:35,296
becomes a quite different type of
planning.

73
00:05:35,296 --> 00:05:40,176
Or, we can have planning problems where
all the agents have all the capabilities

74
00:05:40,176 --> 00:05:43,281
can execute all the operators that are
available.

75
00:05:43,281 --> 00:05:47,752
Or, agents have different capabilities.
So, some operators can only be executed by

76
00:05:47,752 --> 00:05:50,342
certain agents.
Again, we have seen this in the

77
00:05:50,342 --> 00:05:54,762
dock-worker robot domain, where the robots
can transport the containers and the

78
00:05:54,762 --> 00:05:58,527
cranes can load the containers.
And of course, cranes at different

79
00:05:58,527 --> 00:06:02,418
locations can only loan the containers
that are at their locations.

80
00:06:02,419 --> 00:06:06,103
Another aspect of multi-agent planning are
the goals.

81
00:06:06,103 --> 00:06:11,191
So we can have agents with joint goals,so
that all the agents want to achieve the

82
00:06:11,191 --> 00:06:14,095
same goal or they can have individual
goals.

83
00:06:14,095 --> 00:06:18,703
And, this becomes worse when the
individual goals are actually conflicting

84
00:06:18,703 --> 00:06:21,827
or contradictory.
In this case, the agents can be

85
00:06:21,827 --> 00:06:26,726
adversaries, like in a game of chess.
So you can see, there is a whole range of

86
00:06:26,726 --> 00:06:32,116
multi-agent planning problems And another
aspect that is somehow different is the

87
00:06:32,116 --> 00:06:36,277
problem of joint actions.
So, suppose you have a table with some

88
00:06:36,277 --> 00:06:41,282
objects on top of it, and if you lift just
one side of the table, the objects will

89
00:06:41,282 --> 00:06:44,976
fall off.
But if there are two agents that lift both

90
00:06:44,976 --> 00:06:51,048
sides of the table at the same time, then,
the objects will stay on the table because

91
00:06:51,048 --> 00:06:55,304
the table stays level.
This is an example of what is called a

92
00:06:55,304 --> 00:07:01,441
joint action and requires multiple agents
to coordinate to execute that action.

93
00:07:01,441 --> 00:07:07,222
And a single agent alone cannot achieve
the outcome of that joint action alone.
