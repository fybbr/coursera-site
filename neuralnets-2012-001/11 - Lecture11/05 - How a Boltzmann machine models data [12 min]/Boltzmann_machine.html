<!DOCTYPE html>
<html lang="en" dir="ltr" class="client-nojs">
<head>
<title>Boltzmann machine - Scholarpedia</title>
<meta charset="UTF-8" />
<meta name="generator" content="MediaWiki 1.19.17" />
<meta name="citation_title" content="Boltzmann machine" />
<meta name="citation_author" content="Geoffrey E. Hinton" />
<meta name="citation_date" content="2007/5/24" />
<meta name="citation_journal_title" content="Scholarpedia" />
<meta name="citation_issn" content="1941-6016" />
<meta name="citation_volume" content="2" />
<meta name="citation_issue" content="5" />
<meta name="citation_firstpage" content="1668" />
<meta name="citation_doi" content="10.4249/scholarpedia.1668" />
<link rel="shortcut icon" href="/w/images/6/64/Favicon.ico" />
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Scholarpedia (en)" />
<link rel="EditURI" type="application/rsd+xml" href="http://www.scholarpedia.org/w/api.php?action=rsd" />
<link rel="alternate" type="application/atom+xml" title="Scholarpedia Atom feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
<link rel="stylesheet" href="http://www.scholarpedia.org/w/load.php?debug=false&amp;lang=en&amp;modules=mediawiki.legacy.commonPrint%2Cshared%7Cskins.vector&amp;only=styles&amp;skin=vector&amp;*" />
<link rel="stylesheet" href="/w/skins/vector/font-awesome.min.css" />
<link rel="stylesheet" href="/w/skins/vector/local-screen.css" /><meta name="ResourceLoaderDynamicStyles" content="" />
<link rel="stylesheet" href="http://www.scholarpedia.org/w/load.php?debug=false&amp;lang=en&amp;modules=site&amp;only=styles&amp;skin=vector&amp;*" />
<style>a:lang(ar),a:lang(ckb),a:lang(fa),a:lang(kk-arab),a:lang(mzn),a:lang(ps),a:lang(ur){text-decoration:none}a.new,#quickbar a.new{color:#ba0000}

/* cache key: wikidb:resourceloader:filter:minify-css:7:c88e2bcd56513749bec09a7e29cb3ffa */</style>

<script src="http://www.scholarpedia.org/w/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector&amp;*"></script>
<script>if(window.mw){
mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Boltzmann_machine","wgTitle":"Boltzmann machine","wgCurRevisionId":91076,"wgArticleId":1668,"wgIsArticle":true,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Recurrent Neural Networks","Computational Intelligence","Computational Neuroscience","Neural Networks"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgRelevantPageName":"Boltzmann_machine","wgRestrictionEdit":[],"wgRestrictionMove":[],"wgVectorEnabledModules":{"collapsiblenav":true,"collapsibletabs":true,"editwarning":false,"expandablesearch":false,"footercleanup":false,"sectioneditlinks":false,"simplesearch":true,"experiments":true}});
}</script><script>if(window.mw){
mw.loader.implement("user.options",function($){mw.user.options.set({"ccmeonemails":0,"cols":80,"date":"default","diffonly":0,"disablemail":0,"disablesuggest":0,"editfont":"default","editondblclick":0,"editsection":1,"editsectiononrightclick":0,"enotifminoredits":0,"enotifrevealaddr":0,"enotifusertalkpages":1,"enotifwatchlistpages":1,"extendwatchlist":0,"externaldiff":0,"externaleditor":0,"fancysig":0,"forceeditsummary":0,"gender":"unknown","hideminor":0,"hidepatrolled":0,"highlightbroken":1,"imagesize":2,"justify":0,"math":1,"minordefault":0,"newpageshidepatrolled":0,"nocache":0,"noconvertlink":0,"norollbackdiff":0,"numberheadings":0,"previewonfirst":0,"previewontop":1,"quickbar":5,"rcdays":7,"rclimit":50,"rememberpassword":0,"rows":25,"searchlimit":20,"showhiddencats":0,"showjumplinks":1,"shownumberswatching":1,"showtoc":1,"showtoolbar":1,"skin":"vector","stubthreshold":0,"thumbsize":2,"underline":2,"uselivepreview":0,"usenewrc":0,"watchcreations":0,"watchdefault":0,"watchdeletion":0,
"watchlistdays":3,"watchlisthideanons":0,"watchlisthidebots":0,"watchlisthideliu":0,"watchlisthideminor":0,"watchlisthideown":0,"watchlisthidepatrolled":0,"watchmoves":0,"wllimit":250,"vector-simplesearch":1,"vector-collapsiblenav":1,"variant":"en","language":"en","searchNs0":true,"searchNs1":false,"searchNs2":false,"searchNs3":false,"searchNs4":false,"searchNs5":false,"searchNs6":false,"searchNs7":false,"searchNs8":false,"searchNs9":false,"searchNs10":false,"searchNs11":false,"searchNs12":false,"searchNs13":false,"searchNs14":false,"searchNs15":false,"searchNs200":false,"searchNs201":false,"searchNs400":false,"searchNs401":false});;},{},{});mw.loader.implement("user.tokens",function($){mw.user.tokens.set({"editToken":"+\\","watchToken":false});;},{},{});

/* cache key: wikidb:resourceloader:filter:minify-js:7:e87579b4b142a5fce16144e6d8ce1889 */
}</script>
<script>if(window.mw){
mw.loader.load(["mediawiki.page.startup","mediawiki.legacy.wikibits","mediawiki.legacy.ajax"]);
}</script>
<link rel="canonical" href="http://www.scholarpedia.org/article/Boltzmann_machine" />
<!--[if lt IE 7]><style type="text/css">body{behavior:url("/w/skins/vector/csshover.min.htc")}</style><![endif]--></head>
<body class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Boltzmann_machine skin-vector action-view cp-body-published">
		<div id="mw-page-base" class="noprint"></div>
		<div id="mw-head-base" class="noprint"></div>
		<!-- content -->
		<div id="content" class="mw-body">
			<a id="top"></a>
			<div id="mw-js-message" style="display:none;"></div>
						<!-- firstHeading -->
			<h1 id="firstHeading" class="firstHeading">
				<span dir="auto">Boltzmann machine</span>
			</h1>
			<!-- /firstHeading -->

                            <div class="cp-googleplus">
                    <div class="g-plusone" align="right" data-size="small" data-annotation="inline"
                         data-width="180"></div>
                    <script type="text/javascript">
                        (function () {
                            var po = document.createElement('script');
                            po.type = 'text/javascript';
                            po.async = true;
                            po.src = 'https://apis.google.com/js/plusone.js';
                            var s = document.getElementsByTagName('script')[0];
                            s.parentNode.insertBefore(po, s);
                        })();
                    </script>
                </div>
            
			<!-- bodyContent -->
			<div id="bodyContent">
								<!-- tagline -->
				<div id="siteSub">From Scholarpedia</div>
				<!-- /tagline -->
								<!-- subtitle -->
				<div id="contentSub"><span class="subpages"><table class="cp-citation-subtitle" width="100%" cellpadding="0" cellspacing="0" border="0">
<tr valign="bottom">
<td align="left">Geoffrey E. Hinton (2007), Scholarpedia, 2(5):1668.</td>
<td align="center"><a href="http://dx.doi.org/10.4249/scholarpedia.1668">doi:10.4249/scholarpedia.1668</a></td>
<td align="right">revision #91075 [<a href="/w/index.php?title=Boltzmann_machine&amp;action=cite&amp;rev=91075" title="Boltzmann machine">link to/cite this article</a>]</td>
</tr>
</table>
</span></div>
				<!-- /subtitle -->
																<!-- jumpto -->
				<div id="jump-to-nav" class="mw-jump">
					Jump to: <a href="#mw-head">navigation</a>,
					<a href="#p-search">search</a>
				</div>
				<!-- /jumpto -->
								<!-- bodycontent -->
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="cp-box-container"><div class="cp-curator-box noprint"><b><u>Post-publication activity</u></b><br /><button class="cp-button btn"></button><p><span class="cp-title-label">Curator:</span> <a href="/article/User:Geoffrey_E._Hinton" title="User:Geoffrey E. Hinton">Geoffrey E. Hinton</a>
</p><div class="cp-assistants hidden"><div><span class="cp-title-label">Contributors:</span><p>&nbsp;</p></div><div><span>0.50 - </span><p><a href="/article/User:Eugene_M._Izhikevich" title="User:Eugene M. Izhikevich">Eugene M. Izhikevich</a>
</p></div><div><span></span><p><a href="/article/User:Benjamin_Bronner" title="User:Benjamin Bronner">Benjamin Bronner</a>
</p></div><div><span></span><p><a href="/article/User:Barak_Pearlmutter" title="User:Barak Pearlmutter">Barak Pearlmutter</a>
</p></div><div><span></span><p><a href="/article/User:Zoubin_Ghahramani" title="User:Zoubin Ghahramani">Zoubin Ghahramani</a>
</p></div></div></div></div><div class="cp-author-order"><ul id="sp_authors"><li id="sort-1"><p><a href="/article/User:Geoffrey_E._Hinton" title="User:Geoffrey E. Hinton"><span class="bold">Dr. Geoffrey E. Hinton</span>, University of Toronto, CANADA</a>
</p></li></ul></div><p>A <b>Boltzmann machine</b> is a network of symmetrically connected,
neuron-like units that make stochastic decisions about whether to be
on or off. Boltzmann machines have a simple learning <a href="/article/Algorithm" title="Algorithm">algorithm</a> (Hinton &amp; Sejnowski, 1983) that
allows them to discover interesting features that represent complex regularities in the training data. 
The learning algorithm is very slow in networks with
many layers of feature detectors, but it is fast in "restricted Boltzmann machines" that have a single layer of  feature detectors. Many hidden layers can be learned efficiently by <i>composing</i> restricted Boltzmann machines, using the feature activations of 
one as the training data for the next. 
</p><p>Boltzmann machines are used to solve two quite different computational
problems.  For a <i>search</i> problem, the weights on the connections
are fixed and are used to represent a cost function. The stochastic <a href="/article/Dynamical_Systems" title="Dynamical Systems">dynamics</a> of a Boltzmann machine
then allow it to sample binary state vectors that have low values of the cost function.
</p><p>For a <i>learning</i> problem, the Boltzmann machine is shown a set of
binary data vectors and it must learn to generate these vectors with high probability.
To do this, it must find weights on the connections so
that, relative to other possible binary vectors, the data vectors have low values of the cost function.
To solve a learning problem, Boltzmann
machines make many small updates to their weights, and each update
requires them to solve many different search problems.
</p>
<table id="toc" class="toc"><tr><td><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#The_stochastic_dynamics_of_a_Boltzmann_machine"><span class="tocnumber">1</span> <span class="toctext">The stochastic dynamics of a Boltzmann machine</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Learning_in_Boltzmann_machines"><span class="tocnumber">2</span> <span class="toctext">Learning in Boltzmann machines</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#Learning_without_hidden_units"><span class="tocnumber">2.1</span> <span class="toctext">Learning without hidden units</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Learning_with_hidden_units"><span class="tocnumber">2.2</span> <span class="toctext">Learning with hidden units</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-5"><a href="#Different_types_of_Boltzmann_machine"><span class="tocnumber">3</span> <span class="toctext">Different types of Boltzmann machine</span></a>
<ul>
<li class="toclevel-2 tocsection-6"><a href="#Higher-order_Boltzmann_machines"><span class="tocnumber">3.1</span> <span class="toctext">Higher-order Boltzmann machines</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Conditional_Boltzmann_machines"><span class="tocnumber">3.2</span> <span class="toctext">Conditional Boltzmann machines</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="#Mean_field_Boltzmann_machines"><span class="tocnumber">3.3</span> <span class="toctext">Mean field Boltzmann machines</span></a></li>
<li class="toclevel-2 tocsection-9"><a href="#Non-binary_units"><span class="tocnumber">3.4</span> <span class="toctext">Non-binary units</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-10"><a href="#The_speed_of_learning"><span class="tocnumber">4</span> <span class="toctext">The speed of learning</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="#Restricted_Boltzmann_machines"><span class="tocnumber">5</span> <span class="toctext">Restricted Boltzmann machines</span></a>
<ul>
<li class="toclevel-2 tocsection-12"><a href="#Learning_deep_networks_by_composing_restricted_Boltzmann_machines"><span class="tocnumber">5.1</span> <span class="toctext">Learning deep networks by composing restricted Boltzmann machines</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-13"><a href="#Relationships_to_other_models"><span class="tocnumber">6</span> <span class="toctext">Relationships to other models</span></a>
<ul>
<li class="toclevel-2 tocsection-14"><a href="#Markov_random_fields_and_Ising_models"><span class="tocnumber">6.1</span> <span class="toctext">Markov random fields and Ising models</span></a></li>
<li class="toclevel-2 tocsection-15"><a href="#Graphical_models"><span class="tocnumber">6.2</span> <span class="toctext">Graphical models</span></a></li>
<li class="toclevel-2 tocsection-16"><a href="#Gibbs_sampling"><span class="tocnumber">6.3</span> <span class="toctext">Gibbs sampling</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="#Conditional_random_fields"><span class="tocnumber">6.4</span> <span class="toctext">Conditional random fields</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-18"><a href="#References"><span class="tocnumber">7</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-19"><a href="#See_also"><span class="tocnumber">8</span> <span class="toctext">See also</span></a></li>
</ul>
</td></tr></table>
<h2> <span class="mw-headline" id="The_stochastic_dynamics_of_a_Boltzmann_machine">The stochastic dynamics of a Boltzmann machine</span></h2>
<p>When unit \(i\) is given the opportunity to update its binary state, it
first computes its total input, \(z_i\ ,\) which is the sum of its own
bias, \(b_i\ ,\) and the weights on connections coming from other active
units:
<span id="Eq-1">\[\tag{1}
z_i = b_i + \sum_j s_j w_{ij}

\]</span>
</p><p>where \(w_{ij}\) is the weight on the connection between \(i\) and
\(j\ ,\) and \(s_j\) is \(1\) if unit \(j\) is on and \(0\) otherwise. Unit \(i\)
then turns on with a probability given by the logistic function:
<span id="Eq-2">\[\tag{2}
prob(s_i=1) \ \ = \ \ \frac{1}{1+e^{-z_i}}

\]</span>
</p><p><br />
If the units are updated sequentially in any order that
does not depend on their total inputs, the network will eventually
reach a Boltzmann distribution (also called its <a href="/article/Equilibrium" title="Equilibrium">equilibrium</a> or
stationary distribution) in which the probability of a 
state vector, \(v\ ,\) is determined solely by the "energy"
of that state vector relative to the energies of all possible binary
state vectors:
<span id="Eq-3">\[\tag{3}
P(\mathbf{v}) = e^{-E(\mathbf{v})}/\sum_\mathbf{u} e^{-E(\mathbf{u})}

\]</span>
</p><p>As in <a href="/article/Hopfield_Network" title="Hopfield Network">Hopfield nets</a>, the energy of state vector \(\mathbf{v}\) is defined as 
<span id="Eq-4">\[\tag{4}
E(\mathbf{v}) = -\sum_i s^\mathbf{v}_i b_i -\sum_{i&lt;j} s^\mathbf{v}_i
s^\mathbf{v}_j w_{ij}

\]</span>
</p><p>where \(s^\mathbf{v}_i\) is the binary state assigned to unit \(i\) by
state vector \(\mathbf{v}\ .\)
</p><p>If the weights on the connections are chosen so that the energies of
state vectors represent the cost of those state vectors, then the stochastic dynamics of
a Boltzmann machine can be viewed as a way of escaping from poor local
optima while searching for low-cost solutions. The total input to unit
\(i\ ,\) \(z_i\ ,\) represents the difference in energy depending on whether
that unit is off or on, and the fact that unit \(i\) occasionally turns
on even if \(z_i\) is negative means that the energy can occasionally
increase during the search, thus allowing the search to jump over
energy barriers.
</p><p>The search can be improved by using simulated annealing.
This scales down all of the weights and energies
by a factor, \(T\ ,\) which is analogous to the temperature of a physical
system. By reducing T from a large initial value to a small final
value, it is possible to benefit from the fast equilibration at high
temperatures and still have a final equilibrium distribution that
makes low-cost solutions much more probable than high-cost ones. At a
temperature of \(0\) the update rule becomes deterministic and a
Boltzmann machine turns into a <a href="/article/Hopfield_Network" title="Hopfield Network">Hopfield Network</a>
</p>
<h2> <span class="mw-headline" id="Learning_in_Boltzmann_machines">Learning in Boltzmann machines</span></h2>
<h3> <span class="mw-headline" id="Learning_without_hidden_units">Learning without hidden units</span></h3>
<p>Given a training set of state vectors (the data), learning consists
of finding weights and biases (the parameters) that make those state
vectors good.  More specifically, the aim is to find weights and
biases that define a Boltzmann distribution in which the training
vectors have high probability.  By differentiating
Eq. (<a href="#Eq-3">3</a>) and using the fact that \(\partial
E(\mathbf{v})/\partial w_{ij} = - s_i^\mathbf{v}s_j^\mathbf{v}\) it can be
shown that
<span id="Eq-5">\[\tag{5}
\bigg\langle \frac{\partial \log P(\mathbf{v})}{\partial w_{ij}} \bigg\rangle_\mathrm{data} =
\langle s_i s_j \rangle_\mathrm{data} - \langle s_i s_j \rangle_\mathrm{model}

\]</span>
</p><p>where \(\langle \cdot \rangle_\mathrm{data}\) is an expected value in the 
data distribution and \(\langle \cdot \rangle_\mathrm{model}\) is 
an expected value when the Boltzmann machine is sampling
state vectors from its equilibrium distribution at a temperature of
1. To perform gradient ascent in the log probability that the
Boltzmann machine would generate the observed data when sampling from
its equilibrium distribution, \(w_{ij}\) is incremented by a small
learning rate times the RHS of Eq. (<a href="#Eq-5">5</a>). The learning
rule for the bias, \(b_i\ ,\) is the same as Eq. (<a href="#Eq-5">5</a>), but
with \(s_j\) ommitted.
</p><p>If the observed data specifies a binary state for every unit in the
Boltzmann machine, the learning problem is convex: There are no
non-global optima in the parameter space.  However, sampling from 
\(\langle \cdot \rangle_\mathrm{model}\) may involve overcoming energy barriers in the
binary <a href="/article/State_space" title="State space">state space</a>.
</p>
<h3> <span class="mw-headline" id="Learning_with_hidden_units">Learning with hidden units</span></h3>
<p>Learning becomes much more
interesting if the Boltzmann machine consists of some "visible"
units, whose states can be observed, and some "hidden" units whose
states are not specified by the observed data. The hidden units act as
latent variables (features) that allow the Boltzmann machine to model
distributions over visible state vectors that cannot be modelled by
direct pairwise interactions between the visible units. A surprising
property of Boltzmann machines is that, even with hidden units, the
learning rule remains unchanged. This makes it possible to learn
binary features that capture higher-order structure in the data. With
hidden units, the expectation \(\langle s_i s_j \rangle_\mathrm{data}\) is
the average, over all data vectors, of the expected value of \(s_i s_j\)
when a data vector is clamped on the visible units and the hidden
units are repeatedly updated until they reach equilibrium with the
clamped data vector.
</p><p>It is surprising that the learning rule is so simple because \(\partial
\log P(\mathbf{v})/\partial w_{ij}\) depends on all the other weights in
the network. Fortunately, the locally available difference in the two correlations in
Eq. (<a href="#Eq-5">5</a>) tells \(w_{ij}\) everthing it needs to know about
the other weights.  This makes it unnecessary to explicitly propagate
error derivatives, as in the backpropagation algorithm.
</p>
<h2> <span class="mw-headline" id="Different_types_of_Boltzmann_machine">Different types of Boltzmann machine</span></h2>
<h3> <span class="mw-headline" id="Higher-order_Boltzmann_machines">Higher-order Boltzmann machines</span></h3>
<p>The stochastic dynamics and the learning rule can accommodate more
complicated energy functions (Sejnowski, 1986). For example,
the quadratic energy function in Eq. (<a href="#Eq-4">4</a>) can be
replaced by an energy function whose typical term is \(s_i s_j s_k
w_{ijk}\ .\)  The total input to unit \(i\) that is used in the update rule
must then be replaced by \(z_i = b_i + \sum_{j&lt;k} s_j s_k w_{ijk}\ .\)
The only change in the learning rule is that \(s_i s_j\) is replaced by
\(s_i s_j s_k\ .\)
</p>
<h3> <span class="mw-headline" id="Conditional_Boltzmann_machines">Conditional Boltzmann machines</span></h3>
<p>Boltzmann machines model the distribution of the data vectors, but
there is a simple extension for modeling conditional distributions
(Ackley et. al. ,1985).  The only difference between the visible and the
hidden units is that, when sampling \(\langle s_i s_j \rangle_\mathrm{data}\ ,\) the visible units are clamped and the hidden units are not. If
a subset of the visible units are also clamped when sampling \( \langle
s_i s_j \rangle_\mathrm{model} \) this subset acts as "input" units and
the remaining visible units act as "output" units. The same learning
rule applies, but now it maximizes the log probabilities of the
observed output vectors conditional on the input vectors.
</p>
<h3> <span class="mw-headline" id="Mean_field_Boltzmann_machines">Mean field Boltzmann machines</span></h3>
<p>Instead of using units that have stochastic binary states, 
it is possible to use "mean field" units that 
have deterministic, real-valued states between 0 and 1, as in an analog Hopfield net.
Eq. (<a href="#Eq-2">2</a>) is used to compute an "ideal"
value for a unit's state given the current states of the other 
units and the actual value is moved towards the
ideal value by some fraction of the difference. 
If this fraction is small, all the units can be updated in parallel.
The same learning rules can be used by simply replacing the stochastic, 
binary values by the deterministic real-values (Petersen and Andersen, 1987), but 
the learning algorithm is hard to justify and mean field nets have problems 
modeling multi-modal distributions.
</p>
<h3> <span class="mw-headline" id="Non-binary_units">Non-binary units</span></h3>
<p>The binary stochastic units used in Boltzmann machines can be
generalized to "softmax" units that have more than 2 discrete
values, Gaussian units whose output is simply their total input plus
Gaussian noise, binomial units, Poisson units, and any other type of
unit that falls in the exponential family (Welling et. al., 2005). This family is characterized by
the fact that the adjustable parameters have linear effects on the log
probabilities. The general form of the gradient required for
learning is simply the change in the sufficient statistics caused by
clamping data on the visible units.
</p>
<h2> <span class="mw-headline" id="The_speed_of_learning">The speed of learning</span></h2>
<p>Learning is typically very slow in Boltzmann machines with many hidden
layers because large networks can take a long time to approach their
equilibrium distribution, especially when the weights are large and
the equilibrium distribution is highly multimodal, as it usually is
when the visible units are unclamped. Even if samples from the
equilibrium distribution can be obtained, the learning signal is very
noisy because it is the difference of two sampled expectations. These
difficulties can be overcome by restricting the connectivity,
simplifying the learning algorithm, and learning one hidden layer at a
time.
</p>
<h2> <span class="mw-headline" id="Restricted_Boltzmann_machines">Restricted Boltzmann machines</span></h2>
<p>A restricted Boltzmann machine (Smolensky, 1986) consists of a layer of visible
units and a layer of hidden units with no visible-visible or
hidden-hidden connections. With these restrictions, the hidden units
are conditionally independent given a visible vector, so unbiased
samples from \( \langle s_i s_j \rangle_\mathrm{data}\) can be obtained in
one parallel step. To sample from \( \langle s_i s_j \rangle_\mathrm{model}\)
still requires multiple iterations that alternate between updating all
the hidden units in parallel and updating all of the visible units in
parallel.  However, learning still works well if \(\langle s_i s_j
\rangle_\mathrm{model}\) is replaced by \(\langle s_i s_j \rangle_\mathrm{reconstruction}\) which is obtained as follows:
</p>
<ol><li> Starting with a data vector on the visible units, update all of the hidden units in  parallel.  
</li><li> Update all of the visible  units in parallel to get a  "reconstruction".  
</li><li> Update all of the hidden units again.  
</li></ol>
<p>This efficient learning procedure does approximate gradient
descent in a quantity called "contrastive divergence" and works well
in practice (Hinton, 2002).
</p>
<h3> <span class="mw-headline" id="Learning_deep_networks_by_composing_restricted_Boltzmann_machines">Learning deep networks by composing restricted Boltzmann machines</span></h3>
<p>After learning one hidden layer, the activity vectors of the hidden
units, when they are being driven by the real data, can be treated as
"data" for training another restricted Boltzmann machine. This can
be repeated to learn as many hidden layers as desired. After learning
multiple hidden layers in this way, the whole network can be viewed as
a single, multilayer generative model and each additional hidden
layer improves a lower bound on the probability that the
multilayer model would generate the training data (Hinton et. al., 2006).
</p><p>Learning one hidden layer at a time is a very effective way to learn
deep neural networks with many hidden layers and millions of
weights. Even though the learning is unsupervised, the highest level
features are typically much more useful for classification than the
raw data vectors. These deep networks can be fine-tuned to be
better at classification or <a href="/article/Dimensionality_reduction" title="Dimensionality reduction" class="cpstub">dimensionality reduction</a> using the
backpropagation algorithm (Hinton &amp; Salakhutdinov, 2006).  Alternatively, they can be fine-tuned
to be better generative models using a version of the "wake-sleep"
algorithm (Hinton et. al., 2006).
</p>
<h2> <span class="mw-headline" id="Relationships_to_other_models">Relationships to other models</span></h2>
<h3> <span class="mw-headline" id="Markov_random_fields_and_Ising_models">Markov random fields and Ising models</span></h3>
<p>Boltzmann machines are a type of Markov random field, but most Markov
random fields have simple, local interaction weights which are designed by
hand rather than being learned. Boltzmann machines are Ising
models, but Ising models typically use random or hand-designed
interaction weights.
</p>
<h3> <span class="mw-headline" id="Graphical_models">Graphical models</span></h3>
<p>The learning algorithm for Boltzmann machines was the first learning algorithm for undirected graphical models with hidden variables (Jordan 1998). When restricted Boltzmann machines are composed to learn a deep network, the top two layers of the resulting graphical model form an unrestricted Boltzmann machine, but the lower layers form a directed acyclic graph with directed connections from higher layers to lower layers (Hinton et. al. 2006).
</p>
<h3> <span class="mw-headline" id="Gibbs_sampling">Gibbs sampling</span></h3>
<p>The search procedure for Boltzmann machines is an early example of
Gibbs sampling, a <a href="/article/Markov_chain" title="Markov chain">Markov chain</a> Monte Carlo method which was invented
independently (Geman &amp; Geman, 1984) and was also inspired by simulated annealing.
</p>
<h3> <span class="mw-headline" id="Conditional_random_fields"><a href="/article/Conditional_random_fields" title="Conditional random fields">Conditional random fields</a></span></h3>
<p>Conditional random fields (Lafferty et. al., 2001) can be viewed as simplified versions of
higher-order, conditional Boltzmann machines in which the hidden
units have been eliminated. This makes the learning problem convex,
but removes the ability to learn new features.
</p>
<h2> <span class="mw-headline" id="References">References</span></h2>
<ul><li> Ackley, D., Hinton, G., and Sejnowski, T. (1985).  A Learning Algorithm for Boltzmann Machines.  <i>Cognitive Science</i>, 9(1):147-169.
</li></ul>
<ul><li> Geman, S. and Geman, D. (1984).  Stochastic relaxation, Gibbs distributions, and the <a href="/article/Bayesian_statistics" title="Bayesian statistics">Bayesian</a> restoration of images. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 6(6):721-741.
</li></ul>
<ul><li> Hinton, G. E. (2002).  Training products of experts by minimizing contrastive divergence. <i><a href="/article/Neuron" title="Neuron">Neural</a> Computation</i>, 14(8):1711-1800.
</li></ul>
<ul><li> Hinton, G. E, Osindero, S., and Teh, Y. W. (2006).  A fast learning algorithm for <a href="/article/Deep_Belief_Networks" title="Deep Belief Networks">deep belief nets</a>.  <i>Neural Computation</i>, 18:1527-1554.
</li></ul>
<ul><li> Hinton, G. E. and Salakhutdinov, R. R. (2006).  Reducing the dimensionality of data with neural networks. <i>Science</i>, 313:504-507.
</li></ul>
<ul><li> Hinton, G. E. and  Sejnowski, T. J. (1983).  Optimal Perceptual Inference.  <i>Proceedings of the IEEE conference on Computer <a href="/article/Vision" title="Vision">Vision</a> and Pattern Recognition</i>, Washington DC, pp. 448-453.
</li></ul>
<ul><li> Jordan, M. I. (1998) Learning in Graphical Models, MIT press, Cambridge Mass.
</li></ul>
<ul><li> Lafferty, J. and McCallum, A. and Pereira, F. (2001) Conditional random fields: Probabilistic models for segmenting and labeling sequence data. <i>Proc. 18th International Conf. on Machine Learning</i>, pages 282-289 Morgan Kaufmann, San Francisco, CA
</li></ul>
<ul><li> Peterson, C. and Anderson, J.R. (1987), A mean field theory learning algorithm for neural networks.  <i><a href="/article/Complex_Systems" title="Complex Systems">Complex Systems</a></i>, 1(5):995--1019.
</li></ul>
<ul><li> Sejnowski, T. J. (1986).  Higher-order Boltzmann machines.  <i>AIP Conference Proceedings</i>, 151(1):398-403.
</li></ul>
<ul><li> Smolensky, P. (1986).  Information processing in dynamical systems: Foundations of harmony theory.  In Rumelhart, D. E. and McClelland, J. L., editors, <i>Parallel Distributed Processing: Volume 1: Foundations</i>, pages 194-281. MIT Press, Cambridge, MA.
</li></ul>
<ul><li> Welling, M., Rosen-Zvi, M., and Hinton, G. E. (2005). Exponential family harmoniums with an application to information retrieval.  <i>Advances in Neural Information Processing Systems 17</i>, pages 1481-1488. MIT Press, Cambridge, MA.
</li></ul>
<p><b>Internal references</b>
</p>
<ul><li> James Meiss (2007) <a href="/article/Dynamical_systems" title="Dynamical systems">Dynamical systems</a>. <a href="/article/Scholarpedia" title="Scholarpedia">Scholarpedia</a>, 2(2):1629.
</li><li> Eugene M. Izhikevich (2007) <a href="/article/Equilibrium" title="Equilibrium">Equilibrium</a>. Scholarpedia, 2(10):2014.
</li><li> John J. Hopfield (2007) <a href="/article/Hopfield_network" title="Hopfield network">Hopfield network</a>. Scholarpedia, 2(5):1977.
</li></ul>
<h2> <span class="mw-headline" id="See_also">See also</span></h2>
<p><a href="/w/index.php?title=Associative_Memory&amp;action=edit&amp;redlink=1" class="new" title="Associative Memory (page does not exist)">Associative Memory</a>, <a href="/w/index.php?title=Boltzmann_Distribution&amp;action=edit&amp;redlink=1" class="new" title="Boltzmann Distribution (page does not exist)">Boltzmann Distribution</a>, <a href="/article/Hopfield_Network" title="Hopfield Network">Hopfield Network</a>, <a href="/w/index.php?title=Neural_Networks&amp;action=edit&amp;redlink=1" class="new" title="Neural Networks (page does not exist)">Neural Networks</a>, <a href="/w/index.php?title=Simulated_Annealing&amp;action=edit&amp;redlink=1" class="new" title="Simulated Annealing (page does not exist)">Simulated Annealing</a>, <a href="/w/index.php?title=Unsupervised_Learning&amp;action=edit&amp;redlink=1" class="new" title="Unsupervised Learning (page does not exist)">Unsupervised Learning</a>
</p>
<!-- Tidy found serious XHTML errors -->

<!-- 
NewPP limit report
Preprocessor node count: 77/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Expensive parser function count: 0/100
ExtLoops count: 0/100
-->
<div class="cp-footer"><table cellpadding="0" border="0"><tr><td>Sponsored by: <a href="/article/User:Eugene_M._Izhikevich" title="User:Eugene M. Izhikevich"><span>Eugene M. Izhikevich</span>, <span>Editor-in-Chief of Scholarpedia, the peer-reviewed open-access encyclopedia</span></a></td></tr><tr><td><a rel="nofollow" class="external text" href="http://www.scholarpedia.org/w/index.php?title=Boltzmann_machine&amp;oldid=12031">Reviewed by</a>: <a href="/article/User:Anonymous" title="User:Anonymous"><span>Anonymous</span></a></td></tr><tr><td><a rel="nofollow" class="external text" href="http://www.scholarpedia.org/w/index.php?title=Boltzmann_machine&amp;oldid=12477">Reviewed by</a>: <a href="/article/User:Zoubin_Ghahramani" title="User:Zoubin Ghahramani"><span>Dr. Zoubin Ghahramani</span>, <span>Department of Engineering, University of Cambridge, UK, and Carnegie Mellon Univerisity, USA</span></a></td></tr><tr><td><a rel="nofollow" class="external text" href="http://www.scholarpedia.org/w/index.php?title=Boltzmann_machine&amp;oldid=10790">Reviewed by</a>: <a href="/article/User:Barak_Pearlmutter" title="User:Barak Pearlmutter"><span>Dr. Barak Pearlmutter</span>, <span>Hamilton Institute, National University of Ireland Maynooth, Co. Kildare, Ireland</span></a></td></tr><tr><td>Accepted on: <a rel="nofollow" class="external text" href="http://www.scholarpedia.org/w/index.php?title=Boltzmann_machine&amp;oldid=13364">2007-05-24 18:16:00 GMT</a></td></tr></table></div>
</div>				<!-- /bodycontent -->
								<!-- printfooter -->
				<div class="printfooter">
				Retrieved from "<a href="http://www.scholarpedia.org/w/index.php?title=Boltzmann_machine&amp;oldid=91075">http://www.scholarpedia.org/w/index.php?title=Boltzmann_machine&amp;oldid=91075</a>"				</div>
				<!-- /printfooter -->
												<!-- catlinks -->
				<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/article/Special:Categories" title="Special:Categories">Categories</a>: <ul><li><a href="/article/Category:Recurrent_Neural_Networks" title="Category:Recurrent Neural Networks">Recurrent Neural Networks</a></li><li><a href="/article/Category:Computational_Intelligence" title="Category:Computational Intelligence">Computational Intelligence</a></li><li><a href="/article/Category:Computational_Neuroscience" title="Category:Computational Neuroscience">Computational Neuroscience</a></li><li><a href="/article/Category:Neural_Networks" title="Category:Neural Networks">Neural Networks</a></li></ul></div></div>				<!-- /catlinks -->
												<div class="visualClear"></div>
				<!-- debughtml -->
								<!-- /debughtml -->
			</div>
			<!-- /bodyContent -->
		</div>
		<!-- /content -->
		<!-- header -->
		<div id="mw-head" class="noprint">
			
<!-- 0 -->
<div id="p-personal" class="">
	<h5>Personal tools</h5>
	<ul>
		<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Boltzmann+machine" title="You are encouraged to log in; however, it is not mandatory [o]" accesskey="o">Log in / create account</a></li>
	</ul>
</div>

<!-- /0 -->
			<div id="left-navigation">
				
<!-- 0 -->
<div id="p-namespaces" class="vectorTabs">
	<h5>Namespaces</h5>
	<ul>
					<li  id="ca-nstab-main" class="selected"><span><a href="/article/Boltzmann_machine"  title="View the content page [c]" accesskey="c">Page</a></span></li>
					<li  id="ca-talk"><span><a href="/article/Talk:Boltzmann_machine"  title="Discussion about the content page [t]" accesskey="t">Discussion</a></span></li>
			</ul>
</div>

<!-- /0 -->

<!-- 1 -->
<div id="p-variants" class="vectorMenu emptyPortlet">
	<h4>
		</h4>
	<h5><span>Variants</span><a href="#"></a></h5>
	<div class="menu">
		<ul>
					</ul>
	</div>
</div>

<!-- /1 -->
			</div>
			<div id="right-navigation">
				
<!-- 0 -->
<div id="p-views" class="vectorTabs">
	<h5>Views</h5>
	<ul>
					<li id="ca-view" class="selected"><span><a href="/article/Boltzmann_machine" >Read</a></span></li>
					<li id="ca-viewsource"><span><a href="/w/index.php?title=Boltzmann_machine&amp;action=edit"  title="This page is protected.&#10;You can view its source [e]" accesskey="e">View source</a></span></li>
					<li id="ca-history" class="collapsible"><span><a href="/w/index.php?title=Boltzmann_machine&amp;action=history"  title="Past revisions of this page [h]" accesskey="h">View history</a></span></li>
			</ul>
</div>

<!-- /0 -->

<!-- 1 -->
<div id="p-cactions" class="vectorMenu emptyPortlet">
	<h5><span>Actions</span><a href="#"></a></h5>
	<div class="menu">
		<ul>
					</ul>
	</div>
</div>

<!-- /1 -->

<!-- 2 -->
<div id="p-search">
	<h5><label for="searchInput">Search</label></h5>
	<form action="/w/index.php" id="searchform">
				<div id="simpleSearch">
						<input name="search" title="Search Scholarpedia [f]" accesskey="f" id="searchInput" />						<button name="button" title="Search the pages for this text" id="searchButton"><img src="/w/skins/vector/images/search-ltr.png?303" alt="Search" /></button>								<input type='hidden' name="title" value="Special:Search"/>
		</div>
	</form>
</div>

<!-- /2 -->
			</div>
		</div>
		<!-- /header -->
		<!-- panel -->
			<div id="mw-panel" class="noprint">
				<!-- logo -->
					<div id="p-logo"><a style="background-image: url(/w/skins/vector/images/splogo.png);" href="/article/Main_Page"  title="Visit the main page"></a></div>
				<!-- /logo -->
				
<!-- navigation -->
<div class="portal" id='p-navigation'>
	<h5>Navigation</h5>
	<div class="body">
		<ul>
			<li id="n-mainpage-description"><a href="/article/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
			<li id="n-About"><a href="/article/Scholarpedia:About">About</a></li>
			<li id="n-Propose-a-new-article"><a href="/article/Special:ProposeArticle">Propose a new article</a></li>
			<li id="n-Instructions-for-Authors"><a href="/article/Scholarpedia:Instructions_for_Authors">Instructions for Authors</a></li>
			<li id="n-randompage"><a href="/article/Special:Random" title="Load a random page [x]" accesskey="x">Random article</a></li>
			<li id="n-FAQs"><a href="/article/Help:Frequently_Asked_Questions">FAQs</a></li>
			<li id="n-Help"><a href="/article/Scholarpedia:Help">Help</a></li>
			<li id="n-Blog"><a href="http://blog.scholarpedia.org" rel="nofollow">Blog</a></li>
		</ul>
	</div>
</div>

<!-- /navigation -->

<!-- Focal areas -->
<div class="portal" id='p-Focal_areas'>
	<h5>Focal areas</h5>
	<div class="body">
		<ul>
			<li id="n-Astrophysics"><a href="/article/Encyclopedia:Astrophysics">Astrophysics</a></li>
			<li id="n-Celestial-mechanics"><a href="/article/Encyclopedia:Celestial_Mechanics">Celestial mechanics</a></li>
			<li id="n-Computational-neuroscience"><a href="/article/Encyclopedia:Computational_neuroscience">Computational neuroscience</a></li>
			<li id="n-Computational-intelligence"><a href="/article/Encyclopedia:Computational_intelligence">Computational intelligence</a></li>
			<li id="n-Dynamical-systems"><a href="/article/Encyclopedia:Dynamical_systems">Dynamical systems</a></li>
			<li id="n-Physics"><a href="/article/Encyclopedia:Physics">Physics</a></li>
			<li id="n-Touch"><a href="/article/Encyclopedia:Touch">Touch</a></li>
			<li id="n-More-topics"><a href="/article/Scholarpedia:Topics">More topics</a></li>
		</ul>
	</div>
</div>

<!-- /Focal areas -->

<!-- Activity -->
<div class="portal" id='p-Activity'>
	<h5>Activity</h5>
	<div class="body">
		<ul>
			<li id="n-Recently-published-articles"><a href="/article/Special:RecentlyPublished">Recently published articles</a></li>
			<li id="n-Recently-sponsored-articles"><a href="/article/Special:RecentlySponsored">Recently sponsored articles</a></li>
			<li id="n-recentchanges"><a href="/article/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
			<li id="n-All-articles"><a href="/article/Special:AllPages">All articles</a></li>
			<li id="n-List-all-Curators"><a href="/article/Special:ListCurators">List all Curators</a></li>
			<li id="n-List-all-users"><a href="/article/Special:ListUsers">List all users</a></li>
			<li id="n-Journal"><a href="/article/Special:Journal">Scholarpedia Journal</a></li>
		</ul>
	</div>
</div>

<!-- /Activity -->

<!-- SEARCH -->

<!-- /SEARCH -->

<!-- TOOLBOX -->
<div class="portal" id='p-tb'>
	<h5>Tools</h5>
	<div class="body">
		<ul>
			<li id="t-whatlinkshere"><a href="/article/Special:WhatLinksHere/Boltzmann_machine" title="A list of all wiki pages that link here [j]" accesskey="j">What links here</a></li>
			<li id="t-recentchangeslinked"><a href="/article/Special:RecentChangesLinked/Boltzmann_machine" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
			<li id="t-specialpages"><a href="/article/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li>
			<li><a href="/w/index.php?title=Boltzmann_machine&amp;printable=yes" rel="alternate">Printable version</a></li>
			<li id="t-permalink"><a href="/w/index.php?title=Boltzmann_machine&amp;oldid=91075" title="Permanent link to this revision of the page">Permanent link</a></li>
		</ul>
	</div>
</div>

<!-- /TOOLBOX -->

<!-- LANGUAGES -->

<!-- /LANGUAGES -->

                
			</div>
		<!-- /panel -->
		<!-- footer -->
		<div id="footer">

            

            <div id="footer-icons">
                <ul class="social">
                    <li><a href="https://twitter.com/scholarpedia" target="_blank"><img src="/w/skins/vector/images/twitter.png?303" /></a></li>
                    <li><a href="https://plus.google.com/112873162496270574424" target="_blank"><img src="https://ssl.gstatic.com/images/icons/gplus-16.png" /></a></li>
                    <li><a href="http://www.facebook.com/Scholarpedia" target="_blank"><img src="/w/skins/vector/images/facebook.png?303" /></a></li>
                    <li><a href="http://www.linkedin.com/groups/Scholarpedia-4647975/about" target="_blank"><img src="/w/skins/vector/images/linkedin.png?303" /></a></li>
                </ul>

                                    <ul id="footer-icons" class="noprint">
                                                    <li id="footer-poweredbyico">
                                                                    <a href="http://www.mediawiki.org/"><img src="/w/skins/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" width="88" height="31" /></a>                                                                    <a href="http://www.mathjax.org/"><img src="/w/skins/common/images/MathJaxBadge.gif" alt="Powered by MathJax" width="88" height="31" /></a>                                                                    <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US"><img src="/w/skins/common/88x31.png" alt="Creative Commons License" width="88" height="31" /></a>                                                            </li>
                                            </ul>
                            </div>

							<ul id="footer-info">
											<li id="footer-info-copyright">
                <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">"Boltzmann machine"</span> by
            <a xmlns:cc="http://creativecommons.org/ns#" href="http://www.scholarpedia.org/article/Boltzmann_machine" property="cc:attributionName" rel="cc:attributionURL">
                Geoffrey E. Hinton
            </a> is licensed under a
            <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US">
	    Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a>. Permissions beyond the scope of this license are described in the <a xmlns:cc="http://creativecommons.org/ns#" href="http://www.scholarpedia.org/article/Scholarpedia:Terms_of_use" rel="cc:morePermissions">Terms of Use</a></li>
									</ul>
							<ul id="footer-places">
											<li id="footer-places-privacy"><a href="/article/Scholarpedia:Privacy_policy" title="Scholarpedia:Privacy policy">Privacy policy</a></li>
											<li id="footer-places-about"><a href="/article/Scholarpedia:About" class="mw-redirect" title="Scholarpedia:About">About Scholarpedia</a></li>
											<li id="footer-places-disclaimer"><a href="/article/Scholarpedia:General_disclaimer" title="Scholarpedia:General disclaimer">Disclaimers</a></li>
									</ul>
			
			<div style="clear:both"></div>
		</div>
		<!-- /footer -->
		<script src="http://www.scholarpedia.org/w/load.php?debug=false&amp;lang=en&amp;modules=skins.vector&amp;only=scripts&amp;skin=vector&amp;*"></script>
<script>if(window.mw){
mw.loader.load(["jquery.ui.dialog","curatorpedia.dashboard","curatorpedia.confirm","mediawiki.user","mediawiki.page.ready","ext.vector.collapsibleNav","ext.vector.collapsibleTabs","ext.vector.simpleSearch"], null, true);
}</script>
<script>
var wgSitename = 'http://www.scholarpedia.org';</script>

<script type='text/x-mathjax-config'>
//<![CDATA[
    MathJax.Hub.Config({
	styles: { 
	     ".MathJax_Display": { 
	       display: "table-cell ! important", 
	       padding: "1em 0 ! important", 
	       width: (MathJax.Hub.Browser.isMSIE && (document.documentMode||0) < 8 ? 
			 "100% ! important" : "1000em ! important") 
	       } 
        },
        extensions: ["tex2jax.js","TeX/noErrors.js", "TeX/AMSmath.js","TeX/AMSsymbols.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: false,
            element: "content",
            ignoreClass: "(tex2jax_ignore|mw-search-results|searchresults)", /* note: this is part of a regex, check the docs! */
            skipTags: ["script","noscript","style","textarea","code"] /* removed pre as wikimedia renders math in there */
        },
        TeX: {
          Macros: {
            /* Wikipedia compatibility: these macros are used on Wikipedia */
            empty: '\\emptyset',
            P: '\\unicode{xb6}',
            Alpha: '\\unicode{x391}', /* FIXME: These capital Greeks don't show up in bold in \boldsymbol ... */
            Beta: '\\unicode{x392}',
            Epsilon: '\\unicode{x395}',
            Zeta: '\\unicode{x396}',
            Eta: '\\unicode{x397}',
            Iota: '\\unicode{x399}',
            Kappa: '\\unicode{x39a}',
            Mu: '\\unicode{x39c}',
            Nu: '\\unicode{x39d}',
            Pi: '\\unicode{x3a0}',
            Rho: '\\unicode{x3a1}',
            Sigma: '\\unicode{x3a3}',
            Tau: '\\unicode{x3a4}',
            Chi: '\\unicode{x3a7}',
            C: '\\mathbb{C}',        /* the complex numbers */
            N: '\\mathbb{N}',        /* the natural numbers */
            Q: '\\mathbb{Q}',        /* the rational numbers */
            R: '\\mathbb{R}',        /* the real numbers */
            Z: '\\mathbb{Z}',        /* the integer numbers */

            /* some extre macros for ease of use; these are non-standard! */
            F: '\\mathbb{F}',        /* a finite field */
            HH: '\\mathcal{H}',      /* a Hilbert space */
            bszero: '\\boldsymbol{0}', /* vector of zeros */
            bsone: '\\boldsymbol{1}',  /* vector of ones */
            bst: '\\boldsymbol{t}',    /* a vector 't' */
            bsv: '\\boldsymbol{v}',    /* a vector 'v' */
            bsw: '\\boldsymbol{w}',    /* a vector 'w' */
            bsx: '\\boldsymbol{x}',    /* a vector 'x' */
            bsy: '\\boldsymbol{y}',    /* a vector 'y' */
            bsz: '\\boldsymbol{z}',    /* a vector 'z' */
            bsDelta: '\\boldsymbol{\\Delta}', /* a vector '\Delta' */
            E: '\\mathrm{e}',          /* the exponential */
            rd: '\\,\\mathrm{d}',      /*  roman d for use in integrals: $\int f(x) \rd x$ */
            rdelta: '\\,\\delta',      /* delta operator for use in sums */
            rD: '\\mathrm{D}',         /* differential operator D */

            /* example from MathJax on how to define macros with parameters: */
            /* bold: ['{\\bf #1}', 1] */

            RR: '\\mathbb{R}',
            ZZ: '\\mathbb{Z}',
            NN: '\\mathbb{N}',
            QQ: '\\mathbb{Q}',
            CC: '\\mathbb{C}',
            FF: '\\mathbb{F}'
          }
        }
    });
//]]>
//<![CDATA[
MathJax.Hub.config.tex2jax.inlineMath.push(['$','$']);
MathJax.Hub.config.tex2jax.displayMath.push(['$$','$$']);
//]]>
</script>

<script type='text/javascript' src='http://cdn.mathjax.org/mathjax/2.3-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<script src="http://www.scholarpedia.org/w/load.php?debug=false&amp;lang=en&amp;modules=site&amp;only=scripts&amp;skin=vector&amp;*"></script>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-22078568-1");
pageTracker._initData();
pageTracker._trackPageview();
</script><!-- Served in 0.599 secs. -->
        
	</body>
</html>
